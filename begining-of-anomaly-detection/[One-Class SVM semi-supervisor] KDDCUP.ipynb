{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The One-Class SVM is a modified support vector machine model that is well-suited for novelty detection (an example \n",
    "# of semi-supervised anomaly detection ). The idea is that the model trains on normal data and is used to detect \n",
    "# anomalies when new data is presented to it. While the OC-SVM might seem best suited to semi-supervised anomaly \n",
    "# detection, since training on only one class means it’s still “partially labeled” when considering the entire data \n",
    "# set, it can also be used for unsupervised anomaly detection. You will perform semi-supervised anomaly detection on \n",
    "# the same KDDCUP 1999 data set as the isolation forest example. Similar to the isolation forest, the OC-SVM is also \n",
    "# good for high-dimensional data. Additionally, the OC-SVM can capture the shape of the data set pretty well, a point \n",
    "# that will be elaborated upon below.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \n",
    "          \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\",\n",
    "          \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "          \"num_compromised\", \"root_shell\", \"su_attempted\",\n",
    "          \"num_root\", \"num_file_creations\", \"num_shells\", \n",
    "          \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "          \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "          \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "          \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "          \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "          \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "          \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "          \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "           \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "\n",
    "# http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# kddcup.data.gz The full data set (18M; 743M Uncompressed)\n",
    "df = pd.read_csv(\"./data-sample/kddcup.data\", sep=\",\", names=columns, index_col=None)\n",
    "\n",
    "df = df[df[\"service\"] == \"http\"]\n",
    "df = df.drop(\"service\", axis=1)\n",
    "columns.remove(\"service\")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        encoded = LabelEncoder()\n",
    "        encoded.fit(df[col])\n",
    "        df[col] = encoded.transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_encode_value = list(encoded.classes_).index(\"normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelties = df[df[\"label\"] != normal_encode_value]\n",
    "novelties_normal = df[150000: 154045]\n",
    "\n",
    "novelties = pd.concat([novelties, novelties_normal])\n",
    "normal = df[df[\"label\"] == normal_encode_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8090, 41)\n",
      "(619046, 41)\n"
     ]
    }
   ],
   "source": [
    "print(novelties.shape)\n",
    "print(normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(0, 10):\n",
    "    normal = normal.iloc[np.random.permutation(len(normal))]\n",
    "    \n",
    "df2 = pd.concat([normal[:100000], normal[200000:250000]])\n",
    "\n",
    "df_validate = normal[100000:150000]\n",
    "\n",
    "x_train, x_test = train_test_split(df2, test_size = 0.2, random_state = 42)\n",
    "\n",
    "x_val = df_validate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "x_train: (120000, 41) \n",
      "\n",
      "x_test: (30000, 41) \n",
      "\n",
      "x_val: (50000, 41) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes: \\nx_train: {} \\n\".format(x_train.shape))\n",
    "print(\"x_test: {} \\n\".format(x_test.shape))\n",
    "print(\"x_val: {} \\n\".format(x_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What you just did was use a kernel to transform the data into another dimension where there is a clear distinction between the classes of data. This mapping of data is called a kernel trick . There are different types of kernels, including the linear kernel you saw in the earlier examples. Other types of kernels include polynomial kernels, which map the data to some nth dimension using a polynomial function, and exponential kernels, which map the data according to an exponential function.\n",
    "\n",
    "# Another term to cover is regularization , a parameter that tells the SVM how much you want to avoid misclassifications. Lower regularization values lead to graphs like the one you saw earlier where there were a few outliers on either side of the hyperplane. Higher regularization values lead to graphs where you saw the hyperplane separate every single point, at the cost of possibly overfitting on the data.\n",
    "\n",
    "# Gamma tells the SVM how much to consider points farther away from the region of separation between the classes. Higher gamma values tell the SVM to only consider nearby points, while lower gamma values tell the SVM to also consider the points farther away.\n",
    "\n",
    "# Finally, the margin is the separation between each class and the hyperplane. As discussed earlier, an ideal margin involves the maximum equidistant separation of each of the closest from the hyperplane. A bad margin or suboptimal margin has the hyperplane too close to one class or the distance not be as far as it can be to the hyperplane for each point or support vector.\n",
    "\n",
    "# By default, the kernel is set to ‘rbf’, meaning radial basis function. It is similar to the circular decision boundary that you saw in the earlier examples, and you use it here because you want to define a circular boundary around a set of regions that contain normal data. As seen in the earlier examples, any points that fall outside of the region are to be considered anomalies. Gamma tells the model how much you want to consider points further from the hyperplane. Since it is pretty small, this means you want to emphasize the points farther away. The random_state is just a seed for initializing the random number generator, similar to the isolation forest model. The next parameter, nu, specifies how much of the training set contains outliers. Again, you set this to 0.1, similar to the isolation forest model. This acts similar to the regularization parameter that you saw earlier, since it tells the model approximately how many data points you expect the model to misclassify.\n",
    "\n",
    "ocsvm = OneClassSVM(kernel='rbf', gamma=0.00005, random_state=42, nu=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=5e-05, kernel='rbf',\n",
       "      max_iter=-1, nu=0.1, random_state=42, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocsvm.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Accuracy: 89.43%\n",
      "Validation Dataset Accuracy: 89.73%\n"
     ]
    }
   ],
   "source": [
    "# One thing to note is that you can’t get the values for an AUC curve for x_test and x_validation since they comprise entirely of normal data values. You can’t get values for true negative or for false positive since there are no anomalies in the data set to classify falsely as normal or correctly as anomalies.\n",
    "\n",
    "# Also one thing to note: Accuracy in this case is a measure of the percentage of data points in the predictions that are normal data points. Remember, you assumed that around 10% of the data points in the data set are anomalies, so the most optimal “accuracy” to obtain is 90%.\n",
    "\n",
    "preds = ocsvm.predict(x_test)\n",
    "score = 0\n",
    "for f in range(0, x_test.shape[0]):\n",
    "    if(preds[f] == 1):\n",
    "        score = score + 1\n",
    "        \n",
    "accuracy = score / x_test.shape[0]\n",
    "print(\"Test Dataset Accuracy: {:.2%}\".format(accuracy))\n",
    "\n",
    "\n",
    "\n",
    "preds = ocsvm.predict(x_val)\n",
    "score = 0\n",
    "for f in range(0, x_val.shape[0]):\n",
    "    if(preds[f] == 1):\n",
    "        score = score + 1\n",
    "        \n",
    "accuracy = score / x_val.shape[0]\n",
    "print(\"Validation Dataset Accuracy: {:.2%}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 95.91%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This time, you can find the AUC score because there is a 50-50 split between anomalies and normal data. The other two data sets, x_test and x_validation, only had normal data, but this time it is possible for the model to classify false positives and true negatives.\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = ocsvm.predict(novelties)\n",
    "matches = novelties[\"label\"] == normal_encode_value\n",
    "\n",
    "auc = roc_auc_score(preds, matches)\n",
    "print(\"AUC: {:.2%}\".format(auc))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(preds, bins=[-1.5, -0.5] + [0.5, 1.5], align='mid')\n",
    "plt.xticks([-1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
